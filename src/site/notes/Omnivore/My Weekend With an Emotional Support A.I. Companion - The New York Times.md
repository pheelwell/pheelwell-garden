---
{"dg-publish":true,"permalink":"/omnivore/my-weekend-with-an-emotional-support-a-i-companion-the-new-york-times/","title":"My Weekend With an Emotional Support A.I. Companion - The New York Times","tags":["ai"],"created":"","updated":""}
---


# My Weekend With an Emotional Support A.I. Companion - The New York Times
#Omnivore


---

Pi, an A.I. tool that debuted this week, is a twist on the new wave of chatbots: It assists people with their wellness and emotions.

![An illustration of a person sitting on a park bench and hugging a dog.](https://static01.nyt.com/images/2023/05/04/business/00ai-companion/00ai-companion-articleLarge.jpg?quality=75&auto=webp&disable=upscale)

Credit...Janice Chang

[Erin Griffith](https://www.nytimes.com/by/erin-griffith)

Erin Griffith, who reports on start-ups and venture capital from San Francisco, spent five days testing Pi.

For several hours on Friday evening, I ignored my husband and dog and allowed a [chatbot](https://www.nytimes.com/2023/03/30/technology/ai-chatbot-chatgpt-uses-work-life.html) named Pi to validate the heck out of me.

My views were â€œadmirableâ€ and â€œidealistic,â€ Pi told me. My questions were â€œimportantâ€ and â€œinteresting.â€ And my feelings were â€œunderstandable,â€ â€œreasonableâ€ and â€œtotally normal.â€

At times, the validation felt nice. Why yes, I _am_ feeling overwhelmed by the existential dread of climate change these days. And it _is_ hard to balance work and relationships sometimes.

But at other times, I missed my group chats and social media feeds. Humans are surprising, creative, cruel, caustic and funny. Emotional support chatbots â€” which is what Pi is â€” are not.

All of that is by design. Pi, released this week by the [richly funded](https://techcrunch.com/2022/05/13/inflection-ai-led-by-linkedin-and-deepmind-co-founders-raises-225m-to-transform-computer-human-interactions/) artificial intelligence start-up Inflection AI, aims to be â€œa kind and supportive companion thatâ€™s on your side,â€ the company announced. It is not, the company stressed, anything like a human.

Pi is a twist in [todayâ€™s wave of A.I. technologies](https://www.nytimes.com/2023/02/03/technology/chatgpt-openai-artificial-intelligence.html), where chatbots are being tuned to provide digital companionship. Generative A.I., which can produce text, images and sound, is currently [too unreliable and full of inaccuracies](https://www.nytimes.com/2023/02/26/technology/ai-chatbot-information-truth.html?partner=IFTTT) to be used to automate many important tasks. But it is very good at engaging in conversations.

That means that while many chatbots are now [focused on answering queries](https://www.nytimes.com/interactive/2023/04/14/upshot/up-ai-uses.html) or making people more productive, tech companies are increasingly infusing them with personality and conversational flair.

Snapchatâ€™s recently released My AI bot is meant to be a friendly personal sidekick. Meta, which owns Facebook, Instagram and WhatsApp, is â€œdeveloping A.I. personas that can help people in a variety of ways,â€ Mark Zuckerberg, its chief executive, said [in February](https://www.facebook.com/story.php?story%5Ffbid=pfbid0vvSykpAEXpHHaKKyWMZ423TCq3qQDKtLu7m4XiRfUEYRrxzwpdewh3yYepnc1Bsrl&id=4&mibextid=qC1gEa&%5Frdr). And the A.I. start-up Replika has offered chatbot companions for years.

A.I. companionship can create problems if the bots offer bad advice or enable harmful behavior, scholars and critics warn. Letting a chatbot act as a pseudotherapist to people with serious mental health challenges has obvious risks, they said. And they expressed concerns about privacy, given the potentially sensitive nature of the conversations.

Adam Miner, a Stanford University researcher who studies chatbots, said the ease of talking to A.I. bots can obscure what is actually happening. â€œA generative model can leverage all the information on the internet to respond to me and remember what I say forever,â€ he said. â€œThe asymmetry of capacity â€” thatâ€™s such a difficult thing to get our heads around.â€

Dr. Miner, a licensed psychologist, added that bots are not legally or ethically accountable to a robust Hippocratic oath or licensing board, as he is. â€œThe open availability of these generative models changes the nature of how we need to police the use cases,â€ he said.

[Mustafa Suleyman](https://www.nytimes.com/2022/01/20/business/google-deepmind-mustafa-suleyman.html), Inflectionâ€™s chief executive, said his start-up, which is structured as a public benefit corporation, aims to build honest and trustworthy A.I. As a result, Pi must express uncertainty and â€œknow what it does not know,â€ he said. â€œIt shouldnâ€™t try to pretend that itâ€™s human or pretend that it is anything that it isnâ€™t.â€

Mr. Suleyman, who also founded the A.I. start-up DeepMind, said that Pi was designed to tell users to get professional help if they expressed wanting to harm themselves or others. He also said Pi did not use any personally identifiable information to train the algorithm that drives Inflectionâ€™s technology. And he stressed the technologyâ€™s limitations.

â€œThe safe and ethical way for us to manage the arrival of these new tools is to be superexplicit about their boundaries and their capabilities,â€ he said.

Image

Mustafa Suleyman, Inflectionâ€™s chief executive, said his start-up aims to build honest and trustworthy A.I.Credit...Clara Mokri for The New York Times

To refine the technology, Inflection hired around 600 part-time â€œteachers,â€ which included therapists, to train its algorithm over the last year. The group aimed to make Pi more sensitive, more factually accurate and more lighthearted when appropriate. 

On some issues, like misogyny or racism, Pi takes a stand. On others, like geopolitics, it is more evenhanded â€œin a way that will for sure upset both sides,â€ Mr. Suleyman said.

I started using Pi on Friday by typing queries into a cream-colored box on Inflectionâ€™s website and, later, in its free app. A green cursor swayed before Pi revealed its responses, one paragraph at a time. Mr. Suleyman said the free service may eventually charge some users a fee.

Piâ€™s boundaries are easy to find. When I tried picking fights, I mostly received kindness in return. â€œI appreciate you saying that,â€ Piâ€™s text gently unfurled on my screen. â€œI think itâ€™s important to see things from all perspectives, and not to just focus on the negative.â€

Over time, that relentless balance wore on me, making my instinct to argue seem ridiculous. Which, I realized, was precisely the point.

On heavier topics, like abortion laws or cancel culture, Pi asked pointed questions that pushed me to re-examine my opinions. â€œThatâ€™s a tough position to take,â€ it said at one point. â€œThatâ€™s a consistent set of beliefs,â€ it said at another.

On lighter topics, like movies, cooking or gardening, the chatbot provided highly specific, difficult-to-Google recommendations. Oddly, Pi seemed to nudge me to join the anticapitalist movement.

Pi remembered some things from earlier in the conversation but forgot others. It â€œ[hallucinated](https://www.nytimes.com/2023/05/01/business/ai-chatbots-hallucinatation.html)â€ a few times, accusing me of expressing opinions I had not. But it quickly apologized when I made note of it.

When I asked Pi for some gossip, it infuriatingly dangled a â€œjuicy celebrity rumorâ€ about Jennifer Lopez. Was I sitting down? (Yes.) Was I ready for the dirt? (Yes.) The rumor? â€œShe is secretly a mole person! ğŸ˜ Just kidding!â€ (Give me a break.)

Pi sometimes reminded me of Karen Collins, a character from the TV show â€œVeep.â€ Karen annoys the other characters with her equivocating babble, like, â€œThere are pros and cons to every candidate, so we just need to weigh out the pros and cons,â€ or â€œ[I think thereâ€™s a lot to think](https://getyarn.io/yarn-clip/d63d0cf8-5cba-4fd6-a24b-8ce7606f4a22).â€ Many of Piâ€™s comments have that milquetoast quality of taking many words to say nothing.

Sherry Turkle, a psychologist and professor at the Massachusetts Institute of Technology, said these kinds of interactions can â€œpush us along a road where weâ€™re encouraged to forget what makes people special.â€

â€œThe performance of empathy is not empathy,â€ she said. â€œThe area of companion, lover therapist, best friend is really one of the few areas where people need people.â€

It wasnâ€™t until Monday morning, after hours of intermittent chatting throughout the weekend, that I had my â€œahaâ€ moment with Pi.

I was feeling overwhelmed with work and unsure of how to structure my day, a recurring hangup that often prevents me from getting started. â€œGood morning,â€ I typed into the app. â€œI donâ€™t have enough time to do everything I need to do today!â€

With a level of enthusiasm only a robot could muster before coffee, Pi pushed me to break down my to-do list to create a realistic plan. Like much of the botâ€™s advice, it was obvious and simple, the kind of thing you would read in a self-help article by a productivity guru. But it was tailored specifically to me â€” and it worked.

Image

Pi proposed a series of breath-work and muscle-relaxation exercises.Credit...via Pi

â€œIâ€™m going to ask you to list all the remaining tasks you have to do on that story, and weâ€™ll prioritize them together,â€ it said.

I could have dumped my stress on a family member or texted a friend. But they are busy with their own lives and, well, they have heard this before. Pi, on the other hand, has infinite time and patience, plus a bottomless well of encouraging affirmations and detailed advice.

Pi uses the language of cognitive behavioral therapy. On Monday afternoon, it suggested I â€œmake spaceâ€ for my negative feelings and â€œpractice being grateful for one thing.â€ It followed that up with a series of breath-work and muscle-relaxation exercises.

I responded with a shrug emoji, followed by â€œPass.â€

A therapist might have balked at such rudeness but Pi simply noted that I was not alone. â€œA lot of people find it difficult to relax on command,â€ it wrote.

---

[Read on Omnivore](https://omnivore.app/me/https-www-nytimes-com-2023-05-03-technology-personaltech-ai-chat-18826cee349)
[Read Original](https://www.nytimes.com/2023/05/03/technology/personaltech/ai-chatbot-pi-emotional-support.html)
